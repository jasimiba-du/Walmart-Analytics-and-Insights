# -*- coding: utf-8 -*-
"""Advance_EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sJKkuCq59BNVua_DMXI6XIXPhlUyPexQ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df =pd.read_csv('/content/cleaned_data.csv')
df.head(5)

df.dtypes

# First, let's print the current dtypes
print("Original dtypes:")
print(df.dtypes)
print("\n")

# Function to check if a column might contain dates
def is_date_column(column_name):
    date_indicators = ['date', 'datetime', 'time', 'year', 'month', 'day']
    return any(indicator in column_name.lower() for indicator in date_indicators)

# Convert date columns with explicit format
for col in df.columns:
    if df[col].dtype == 'object':
        # Check if column name suggests it might contain dates
        if is_date_column(col):
            try:
                # First attempt: Try common date format
                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')
            except ValueError:
                try:
                    # Second attempt: Try another common format
                    df[col] = pd.to_datetime(df[col], format='%d-%m-%Y')
                except ValueError:
                    try:
                        # Last attempt: Let pandas infer the format
                        df[col] = pd.to_datetime(df[col])
                        print(f"Column '{col}' converted to datetime using inferred format")
                    except ValueError:
                        print(f"Warning: Could not convert column '{col}' to datetime")

# Print the updated dtypes
print("\nUpdated dtypes:")
print(df.dtypes)

# Optional: Display a sample of the date columns to verify conversion
date_columns = df.select_dtypes(include=['datetime64[ns]']).columns
if len(date_columns) > 0:
    print("\nSample of date columns:")
    print(df[date_columns].head())

# prompt: find out unique column in rating

# Assuming 'rating' is a column in your DataFrame 'df'
unique_ratings = df['rating'].unique()
unique_ratings

"""**Rating impact on total sales**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define the rating ranges (5 groups)
rating_bins = [0, 4, 5, 6, 8, 10]
rating_labels = ['0-4', '4-5', '5-6', '6-8', '8-10']

# Create a new column in the dataframe that assigns the appropriate category based on rating
df['rating_category'] = pd.cut(df['rating'], bins=rating_bins, labels=rating_labels, right=False)

# Group by rating category and calculate total sales for each category
sales_by_rating_category = df.groupby('rating_category')['total_price'].sum()

# Plotting the sales impact by rating category
plt.figure(figsize=(10, 6))
sns.barplot(x=sales_by_rating_category.index, y=sales_by_rating_category.values, palette="viridis")
plt.title('Sales Impact by Rating Category')
plt.xlabel('Rating Category')
plt.ylabel('Total Sales')
plt.xticks(rotation=0)
plt.show()

# Define the new rating bins and labels
rating_bins = [0, 4, 5, 6, 8, 10]  # Define rating ranges
rating_labels = ['0-4', '4-5', '5-6', '6-8', '8-10']  # Define the corresponding labels

# Create a new column for the rating categories
df['rating_category'] = pd.cut(df['rating'], bins=rating_bins, labels=rating_labels, right=False)

# Now, group by rating_category and category, and count the occurrences
category_by_rating = df.groupby(['rating_category', 'category']).size().reset_index(name='count')


# Optionally, pivot the table for a clearer view
pivot_table = category_by_rating.pivot(index='rating_category', columns='category', values='count').fillna(0)

plt.figure(figsize=(12, 6))
sns.heatmap(pivot_table, annot=True, fmt=".0f", cmap="YlGnBu", linewidths=.5)
plt.title('Pivot Table of Rating Categories by Category')
plt.xlabel('Category')
plt.ylabel('Rating Category')
plt.show()



"""**Profit Margin by Category**"""

plt.figure(figsize=(12, 6))
sns.barplot(x='category', y='profit_margin', data=df, ci=None, palette='coolwarm')
plt.title("Profit Margins by Category")
plt.xlabel("Category")
plt.ylabel("Profit Margin")
plt.xticks(rotation=45)
plt.show()

"""**2. Payment Method Preferences**"""

plt.figure(figsize=(8, 6))
payment_counts = df['payment_method'].value_counts()
payment_counts.plot(kind='pie', autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Set3'))
plt.title("Payment Method Distribution")
plt.ylabel("")
plt.show()

"""**Branch-wise Performance (Total Sales by Branch)**"""

import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Group by 'branch' and calculate total sales
branch_sales = df.groupby('branch')['total_price'].sum().reset_index()

# Step 2: Sort branches by total sales (descending for highest, ascending for lowest)
top_10_branches = branch_sales.sort_values(by='total_price', ascending=False).head(10)
lowest_10_branches = branch_sales.sort_values(by='total_price', ascending=True).head(10)

# Step 3: Plot top 10 branches
plt.figure(figsize=(12, 6))
sns.barplot(x='branch', y='total_price', data=top_10_branches, palette='Blues_d')
plt.title("Top 10 Highest Sales Branches")
plt.xlabel("Branch")
plt.ylabel("Total Sales")
plt.xticks(rotation=45)
plt.show()

# Step 4: Plot lowest 10 branches
plt.figure(figsize=(12, 6))
sns.barplot(x='branch', y='total_price', data=lowest_10_branches, palette='Reds_d')
plt.title("Top 10 Lowest Sales Branches")
plt.xlabel("Branch")
plt.ylabel("Total Sales")
plt.xticks(rotation=45)
plt.show()

"""**Time of Day Sales Trends (Hourly Sales)**"""

hourly_sales = df.groupby('hour')['total_price'].sum().reset_index()

plt.figure(figsize=(12, 6))
sns.lineplot(x='hour', y='total_price', data=hourly_sales, marker="o")
plt.title("Hourly Sales Trends")
plt.xlabel("Hour of Day")
plt.ylabel("Total Sales")
plt.grid()
plt.show()

from scipy.stats import ttest_ind

# Extract ratings based on payment method
ewallet_ratings = df[df['payment_method'] == 'Ewallet']['rating']
cash_ratings = df[df['payment_method'] == 'Cash']['rating']

# Perform t-test
t_stat, p_value = ttest_ind(ewallet_ratings, cash_ratings)

print("\nHypothesis Testing: Payment Method vs Ratings")
print(f"T-statistic: {t_stat:.2f}, P-value: {p_value:.4f}")
if p_value < 0.05:
    print("Reject the null hypothesis: Payment method significantly affects ratings.")
else:
    print("Fail to reject the null hypothesis: Payment method does not significantly affect ratings.")

# Plotting the relationship between Payment Method and Rating
plt.figure(figsize=(12, 6))
sns.boxplot(x='payment_method', y='rating', data=df, palette='Set2')
plt.title('Relationship Between Payment Method and Rating')
plt.xlabel('Payment Method')
plt.ylabel('Rating')
plt.xticks(rotation=45)
plt.show()

"""**Principal Component Analysis (PCA)**"""

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

numerical_data = df.select_dtypes(include=['float64', 'int64']).dropna()
scaled_data = StandardScaler().fit_transform(numerical_data)
pca = PCA(n_components=2)
pca_result = pca.fit_transform(scaled_data)

plt.scatter(pca_result[:, 0], pca_result[:, 1], c=df['category'].factorize()[0], cmap='viridis')
plt.title('PCA Visualization')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.show()

"""**Chi-Square Test (Categorical vs Categorical)**"""

from scipy.stats import chi2_contingency

contingency_table = pd.crosstab(df['payment_method'], df['category'])
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Chi2 Statistic: {chi2}, P-value: {p}")

"""**ANOVA (Categorical vs Numerical)**"""

from scipy.stats import f_oneway

groups = [df[df['category'] == cat]['profit_margin'] for cat in df['category'].unique()]
f_stat, p_value = f_oneway(*groups)

print(f"ANOVA Results - F-statistic: {f_stat}, P-value: {p_value}")

"""**Use the Variance Inflation Factor (VIF)**"""

from statsmodels.stats.outliers_influence import variance_inflation_factor

X = df.select_dtypes(include=['float64', 'int64']).dropna()
vif_data = pd.DataFrame()
vif_data['feature'] = X.columns
vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
print(vif_data)